{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequence modeling to predict next most likely term using RNN and Transformer\n",
    "\n",
    "#RNN\n",
    "!pip install tensorflow\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample data\n",
    "sentences = [\n",
    "    'how to use tensorflow',\n",
    "    'what is machine learning',\n",
    "    'deep learning with neural networks'\n",
    "]\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create sequences\n",
    "sequences = []\n",
    "for sentence in sentences:\n",
    "    encoded = tokenizer.texts_to_sequences([sentence])[0]\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequences.append(encoded[:i+1])\n",
    "\n",
    "# Pad sequences\n",
    "max_len = max(len(seq) for seq in sequences)\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "\n",
    "# Create input and output\n",
    "X, y = sequences[:, :-1], sequences[:, -1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "\n",
    "# Model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=total_words, output_dim=10, input_length=X.shape[1]),\n",
    "    SimpleRNN(50, return_sequences=False),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train\n",
    "model.fit(X, y, epochs=10, verbose=1)\n",
    "\n",
    "# Predict next term\n",
    "def predict_next_term(model, tokenizer, text):\n",
    "    encoded = tokenizer.texts_to_sequences([text])[0]\n",
    "    encoded = pad_sequences([encoded], maxlen=X.shape[1], padding='pre')\n",
    "    prediction = model.predict(encoded)\n",
    "    predicted_word_index = np.argmax(prediction, axis=-1)[0]\n",
    "    return tokenizer.index_word.get(predicted_word_index, '')\n",
    "\n",
    "print(predict_next_term(model, tokenizer, 'how to use'))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
